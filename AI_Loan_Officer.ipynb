{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The AI Loan Officer: Final Version (v6)\n",
    "### With Enhanced Gig Worker Logic, Lenient Rules, and Comprehensive Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "setup-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Setup complete. All libraries imported and configuration set.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "import xgboost as xgb\n",
    "\n",
    "# Suppress warnings for a cleaner notebook\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# --- Configuration -- -\n",
    "DATA_PATH = \"modified_dataset.csv\"\n",
    "CLASSIFIER_MODEL_PATH = \"best_loan_approval_pipeline.joblib\"\n",
    "INTEREST_MODEL_PATH = \"interest_rate_model.joblib\"\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.20\n",
    "\n",
    "print(\"✅ Setup complete. All libraries imported and configuration set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading & Gig-Worker-Centric Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "feature-engineering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Feature engineering applied successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>savings_log_capped</th>\n",
       "      <th>total_tenure_months</th>\n",
       "      <th>gig_performance_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.126671</td>\n",
       "      <td>57</td>\n",
       "      <td>1861.312820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>23</td>\n",
       "      <td>1399.870614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>23</td>\n",
       "      <td>947.689897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.210440</td>\n",
       "      <td>34</td>\n",
       "      <td>1417.365832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>109</td>\n",
       "      <td>2092.364686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   savings_log_capped  total_tenure_months  gig_performance_score\n",
       "0           10.126671                   57            1861.312820\n",
       "1            0.000000                   23            1399.870614\n",
       "2            0.000000                   23             947.689897\n",
       "3            9.210440                   34            1417.365832\n",
       "4            0.000000                  109            2092.364686"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def engineer_features(df):\n",
    "    \"\"\"\n",
    "    Creates a suite of powerful, context-rich features.\n",
    "    `savings_to_income_ratio` has been removed.\n",
    "    \"\"\"\n",
    "    df_eng = df.copy()\n",
    "    \n",
    "    for col in ['avg_monthly_earnings', 'loan_amount_requested', 'savings', 'recurring_expenses', \n",
    "                'tenure_platform_1_months', 'tenure_platform_2_months', 'rating', 'working_hours_per_day']:\n",
    "        if col in df_eng.columns:\n",
    "            df_eng[col] = pd.to_numeric(df_eng[col], errors='coerce').fillna(0)\n",
    "\n",
    "    # Cap and Log Transform Savings\n",
    "    capped_savings = df_eng['savings'].clip(upper=200000)\n",
    "    df_eng['savings_log_capped'] = np.log1p(capped_savings)\n",
    "    \n",
    "    df_eng['avg_monthly_earnings'] = df_eng['avg_monthly_earnings'].clip(lower=1)\n",
    "    df_eng['loan_to_income_ratio'] = df_eng['loan_amount_requested'] / df_eng['avg_monthly_earnings']\n",
    "    df_eng['total_tenure_months'] = df_eng['tenure_platform_1_months'] + df_eng['tenure_platform_2_months']\n",
    "    df_eng['disposable_income'] = df_eng['avg_monthly_earnings'] - df_eng['recurring_expenses']\n",
    "    \n",
    "    log_tenure = np.log1p(df_eng['total_tenure_months'])\n",
    "    log_avg_earnings = np.log1p(df_eng['avg_monthly_earnings'])\n",
    "    df_eng['gig_performance_score'] = (\n",
    "        df_eng['rating'] * log_tenure * log_avg_earnings * df_eng['working_hours_per_day']\n",
    "    ).fillna(0)\n",
    "    \n",
    "    return df_eng\n",
    "# --- Load and Process Data ---\n",
    "df_raw = pd.read_csv(DATA_PATH)\n",
    "df_processed = engineer_features(df_raw)\n",
    "\n",
    "print(\"✅ Feature engineering applied successfully.\")\n",
    "df_processed[['savings_log_capped','total_tenure_months', 'gig_performance_score']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training Pipeline\n",
    "The model is now trained with `credit_card_user` and the new `gig_performance_score` as key features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "model-training",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Feature engineering applied successfully.\n",
      "⏳ Starting model re-training with new feature logic...\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "\n",
      "✅ Re-training complete. New model saved to best_loan_approval_pipeline.joblib\n"
     ]
    }
   ],
   "source": [
    "# 1. Apply the updated feature engineering\n",
    "df_processed = engineer_features(df_raw)\n",
    "print(\"✅ Feature engineering applied successfully.\")\n",
    "\n",
    "# 2. Define the final feature set, now excluding savings_to_income_ratio\n",
    "TARGET = 'repayment_status'\n",
    "NUMERIC_FEATURES = [\n",
    "    'age', 'working_hours_per_day', 'rating', 'avg_monthly_earnings', \n",
    "    'savings_log_capped',\n",
    "    'dependent_count', 'credit_score', 'credit_history_length_months', 'loan_amount_requested',\n",
    "    'recurring_expenses', 'total_tenure_months', 'loan_to_income_ratio', \n",
    "    'disposable_income', 'gig_performance_score'\n",
    "]\n",
    "CATEGORICAL_FEATURES = [\n",
    "    'gender', 'platform_primary', 'sector', 'education', 'purpose_of_loan', 'location_stability', 'credit_card_user'\n",
    "]\n",
    "FEATURES = NUMERIC_FEATURES + CATEGORICAL_FEATURES\n",
    "\n",
    "# Ensure all features exist before creating X\n",
    "existing_features = [f for f in FEATURES if f in df_processed.columns]\n",
    "X = df_processed[existing_features]\n",
    "y = df_processed[TARGET]\n",
    "\n",
    "# 3. Split data and train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y)\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='median')), ('scaler', StandardScaler())])\n",
    "categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')), ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, [f for f in NUMERIC_FEATURES if f in X.columns]),\n",
    "    ('cat', categorical_transformer, [f for f in CATEGORICAL_FEATURES if f in X.columns])\n",
    "], remainder='passthrough')\n",
    "\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', xgb.XGBClassifier(random_state=RANDOM_STATE, use_label_encoder=False, eval_metric='logloss'))\n",
    "])\n",
    "\n",
    "param_dist = {\n",
    "    'classifier__n_estimators': [200, 300, 400],\n",
    "    'classifier__learning_rate': [0.05, 0.1],\n",
    "    'classifier__max_depth': [5, 7, 9],\n",
    "    'classifier__subsample': [0.8, 0.9],\n",
    "    'classifier__colsample_bytree': [0.8, 0.9]\n",
    "}\n",
    "random_search = RandomizedSearchCV(\n",
    "    model_pipeline, param_distributions=param_dist, n_iter=15, \n",
    "    cv=5, scoring='roc_auc', n_jobs=-1, random_state=RANDOM_STATE, verbose=1\n",
    ")\n",
    "\n",
    "print(\"⏳ Starting model re-training with new feature logic...\")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "best_pipeline = random_search.best_estimator_\n",
    "joblib.dump(best_pipeline, CLASSIFIER_MODEL_PATH)\n",
    "\n",
    "print(f\"\\n✅ Re-training complete. New model saved to {CLASSIFIER_MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Training the Interest Rate Prediction Model...\n",
      "Finding best hyperparameters for the interest rate model...\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\nInterest Rate Model Evaluation:\n",
      "Mean Absolute Error (MAE): 3.45% (On average, the prediction is off by this many percentage points)\n",
      "R-squared (R²): -0.01\n",
      "\\n✅ Interest Rate Model trained, evaluated, and saved to interest_rate_model.joblib\n"
     ]
    }
   ],
   "source": [
    "# --- ADD THIS NEW, IMPROVED CELL TO YOUR JUPYTER NOTEBOOK ---\n",
    "\n",
    "print(\"⏳ Training the Interest Rate Prediction Model...\")\n",
    "\n",
    "# The target is the original interest rate for loans that were successfully repaid\n",
    "rate_df = df_processed[df_processed['repayment_status'] == 1].copy()\n",
    "rate_df['interest_rate'].fillna(rate_df['interest_rate'].median(), inplace=True)\n",
    "\n",
    "X_rate = rate_df[FEATURES]\n",
    "y_rate = rate_df['interest_rate']\n",
    "\n",
    "# Split data for evaluation\n",
    "X_rate_train, X_rate_test, y_rate_train, y_rate_test = train_test_split(X_rate, y_rate, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
    "\n",
    "# We use the same preprocessor pipeline defined in the classifier training cell\n",
    "interest_rate_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', xgb.XGBRegressor(objective='reg:squarederror', random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "# --- NEW: Hyperparameter Tuning for the Regressor ---\n",
    "regressor_param_dist = {\n",
    "    'regressor__n_estimators': [100, 200, 300],\n",
    "    'regressor__learning_rate': [0.05, 0.1, 0.2],\n",
    "    'regressor__max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "regressor_search = RandomizedSearchCV(\n",
    "    interest_rate_pipeline, param_distributions=regressor_param_dist, n_iter=10, \n",
    "    cv=5, scoring='neg_mean_absolute_error', n_jobs=-1, random_state=RANDOM_STATE, verbose=1\n",
    ")\n",
    "\n",
    "print(\"Finding best hyperparameters for the interest rate model...\")\n",
    "regressor_search.fit(X_rate_train, y_rate_train)\n",
    "\n",
    "best_interest_rate_model = regressor_search.best_estimator_\n",
    "\n",
    "# --- NEW: Evaluation Step ---\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "y_rate_pred = best_interest_rate_model.predict(X_rate_test)\n",
    "mae = mean_absolute_error(y_rate_test, y_rate_pred)\n",
    "r2 = r2_score(y_rate_test, y_rate_pred)\n",
    "\n",
    "print(f\"\\\\nInterest Rate Model Evaluation:\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}% (On average, the prediction is off by this many percentage points)\")\n",
    "print(f\"R-squared (R²): {r2:.2f}\")\n",
    "\n",
    "\n",
    "# Save the best trained regressor model\n",
    "joblib.dump(best_interest_rate_model, INTEREST_MODEL_PATH)\n",
    "\n",
    "print(f\"\\\\n✅ Interest Rate Model trained, evaluated, and saved to {INTEREST_MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "model-evaluation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Evaluating the best model on the test set...\n",
      "\n",
      "Test Set ROC-AUC Score: 0.9343\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.86      0.86      2066\n",
      "         1.0       0.85      0.84      0.85      1934\n",
      "\n",
      "    accuracy                           0.85      4000\n",
      "   macro avg       0.85      0.85      0.85      4000\n",
      "weighted avg       0.85      0.85      0.85      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"📊 Evaluating the best model on the test set...\\n\")\n",
    "y_pred = best_pipeline.predict(X_test)\n",
    "y_proba = best_pipeline.predict_proba(X_test)[:, 1]\n",
    "print(f\"Test Set ROC-AUC Score: {roc_auc_score(y_test, y_proba):.4f}\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Preparing the SHAP Explainer\n",
    "We initialize the SHAP explainer here to make it available for our inference engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "shap-prep",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠 Initializing SHAP explainer for advanced reasoning...\n",
      "✅ SHAP explainer is ready.\n"
     ]
    }
   ],
   "source": [
    "print(\"🧠 Initializing SHAP explainer for advanced reasoning...\")\n",
    "\n",
    "classifier = best_pipeline.named_steps['classifier']\n",
    "preprocessor = best_pipeline.named_steps['preprocessor']\n",
    "\n",
    "try:\n",
    "    ohe_feature_names = preprocessor.named_transformers_['cat'].named_steps['onehot'].get_feature_names_out(CATEGORICAL_FEATURES)\n",
    "    TRANSFORMED_FEATURE_NAMES = NUMERIC_FEATURES + list(ohe_feature_names)\n",
    "except Exception:\n",
    "    TRANSFORMED_FEATURE_NAMES = FEATURES\n",
    "\n",
    "explainer = shap.TreeExplainer(classifier)\n",
    "\n",
    "print(\"✅ SHAP explainer is ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. The AI Loan Officer: Inference Engine (Final Version)\n",
    "This is the final prediction engine. It now includes:\n",
    "1.  **Gig Worker-Centric Rules**: Fast-tracks approvals for strong gig workers.\n",
    "2.  **Traditional Finance Rules**: Fast-tracks approvals for gig workers with strong traditional finances (savings, assets, credit card).\n",
    "3.  **SHAP Reasoning Engine**: Translates complex model outputs into human-readable reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "inference-engine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ AI Loan Officer engine v6 (with Enhanced Gig Worker Logic) is ready.\n"
     ]
    }
   ],
   "source": [
    "def apply_business_rules(applicant_data):\n",
    "    \"\"\"Checks for hardcoded rules with a focus on gig worker strengths.\"\"\"\n",
    "    \n",
    "    # --- Auto-Approvals for Strong Profiles ---\n",
    "    if applicant_data.get('gig_performance_score', 0) > 850 and applicant_data.get('rating', 0) >= 4.6:\n",
    "         return {\"decision\": \"Approve\", \"reason\": \"Rule: Strong & consistent gig worker profile.\"}\n",
    "    \n",
    "    if str(applicant_data.get('credit_card_user', 'No')).lower() == 'yes' and applicant_data.get('savings', 0) > 25000 and applicant_data.get('total_assets', 0) > 50000:\n",
    "        return {\"decision\": \"Approve\", \"reason\": \"Rule: Strong traditional financial indicators.\"}\n",
    "    if applicant_data.get('credit_score', 0) > 750 and applicant_data.get('loan_to_income_ratio', 100) < 1.5:\n",
    "        return {\"decision\": \"Approve\", \"reason\": \"Rule: Excellent traditional financial profile.\"}\n",
    "    \n",
    "    # --- Hard Rejects (Non-negotiable) ---\n",
    "    if applicant_data.get('age', 25) < 21:\n",
    "        return {\"decision\": \"Reject\", \"reason\": \"Rule: Applicant must be at least 21.\"}\n",
    "    if applicant_data.get('avg_monthly_earnings', 0) < 10000:\n",
    "        return {\"decision\": \"Reject\", \"reason\": \"Rule: Minimum monthly income not met.\"}\n",
    "    if applicant_data.get('credit_score', 0) < 400:\n",
    "        return {\"decision\": \"Reject\", \"reason\": \"Rule: Credit score is below minimum.\"}\n",
    "    if applicant_data.get('loan_to_income_ratio', 100) > 6.0:\n",
    "        return {\"decision\": \"Reject\", \"reason\": \"Rule: Loan-to-income ratio is too high.\"}\n",
    "    if applicant_data.get('loan_amount_requested', 0) > 500000:\n",
    "         return {\"decision\": \"Reject\", \"reason\": \"Rule: Loan amount exceeds maximum.\"}\n",
    "    \n",
    "    return None # No rule triggered, proceed to AI model\n",
    "\n",
    "def get_shap_reasoning(shap_values, feature_names, top_n=2):\n",
    "    sv = pd.Series(shap_values, index=feature_names)\n",
    "    friendly_names = {name: name.replace('_', ' ').replace('num__', '').replace('cat__', '') for name in feature_names}\n",
    "    sv.index = sv.index.map(friendly_names)\n",
    "    pos_contributors = sv.nlargest(top_n)\n",
    "    neg_contributors = sv.nsmallest(top_n)\n",
    "    pos_str = \", \".join(pos_contributors.index)\n",
    "    neg_str = \", \".join(neg_contributors.index)\n",
    "    reason = f\"AI Model (Positives: {pos_str} | Concerns: {neg_str})\"\n",
    "    return reason\n",
    "\n",
    "def make_loan_decision(applicant_data):\n",
    "    if isinstance(applicant_data, dict):\n",
    "        applicant_df = pd.DataFrame([applicant_data])\n",
    "    else: \n",
    "        applicant_df = pd.DataFrame(applicant_data).T\n",
    "    \n",
    "    applicant_df_eng = engineer_features(applicant_df)\n",
    "    rule_result = apply_business_rules(applicant_df_eng.iloc[0].to_dict())\n",
    "    \n",
    "    final_decision, reason, probability = \"Error\", \"Internal Error\", 0.0\n",
    "    sanctioned_amount, interest_rate, loan_term = 0, 0, 0\n",
    "    \n",
    "    if rule_result:\n",
    "        final_decision, reason = rule_result['decision'], rule_result['reason']\n",
    "        if final_decision == 'Approve':\n",
    "            probability = 1.0\n",
    "            sanctioned_amount = applicant_df_eng.iloc[0]['loan_amount_requested']\n",
    "            interest_rate, loan_term = 14.0, 36\n",
    "    else:\n",
    "        try:\n",
    "            pipeline = joblib.load(MODEL_PATH)\n",
    "            applicant_transformed = pipeline.named_steps['preprocessor'].transform(applicant_df_eng[FEATURES])\n",
    "            probability = pipeline.named_steps['classifier'].predict_proba(applicant_transformed)[:, 1][0]\n",
    "            \n",
    "            shap_vals = explainer.shap_values(applicant_transformed)[0]\n",
    "            reason = get_shap_reasoning(shap_vals, TRANSFORMED_FEATURE_NAMES)\n",
    "\n",
    "            if probability < 0.5 and applicant_df_eng.iloc[0]['rating'] >= 4.5 and applicant_df_eng.iloc[0]['total_tenure_months'] >= 12:\n",
    "                final_decision = \"Manual Review\"\n",
    "                reason += \" | Flagged for review due to high rating & tenure.\"\n",
    "            elif probability >= 0.50:\n",
    "                final_decision = \"Approve\"\n",
    "                if probability >= 0.85: sanction_factor, interest_rate, loan_term = 1.0, 14.5, 36\n",
    "                elif probability >= 0.70: sanction_factor, interest_rate, loan_term = 0.85, 17.5, 24\n",
    "                else: sanction_factor, interest_rate, loan_term = 0.70, 20.5, 12\n",
    "                sanctioned_amount = min(round(applicant_df_eng.iloc[0]['loan_amount_requested'] * sanction_factor, -3), applicant_df_eng.iloc[0]['loan_amount_requested'])\n",
    "            else:\n",
    "                final_decision = \"Reject\"\n",
    "\n",
    "        except Exception as e:\n",
    "            final_decision, reason = \"Error\", f\"Prediction Error: {e}\"\n",
    "\n",
    "    return {\n",
    "        \"name\": applicant_df.get('name', 'Unknown').iloc[0],\n",
    "        \"decision\": final_decision,\n",
    "        \"reason\": reason,\n",
    "        \"model_confidence_score\": float(round(probability, 4)),\n",
    "        \"final_sanctioned_amount\": sanctioned_amount,\n",
    "        \"interest_rate_pct\": interest_rate,\n",
    "        \"loan_term_months\": loan_term\n",
    "    }\n",
    "\n",
    "print(\"✅ AI Loan Officer engine v6 (with Enhanced Gig Worker Logic) is ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Final Demonstration\n",
    "The final output table is now merged with the applicant's input data for a complete, contextual view of each decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "demonstration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 2 new applications from your file.\n",
      "\n",
      "\n",
      "--- 🦾 AI Loan Officer Decisions ---\n",
      "| name    |   age |   avg_monthly_earnings |   rating |   loan_amount_requested | decision   |   final_sanctioned_amount |   interest_rate_pct |   loan_term_months |   loan_term_months |   model_confidence_score | reason                                                                                                               |\n",
      "|:--------|------:|-----------------------:|---------:|------------------------:|:-----------|--------------------------:|--------------------:|-------------------:|-------------------:|-------------------------:|:---------------------------------------------------------------------------------------------------------------------|\n",
      "| Samay   |    25 |                  30000 |        4 |                   10000 | Approve    |                     10000 |                14.5 |                 36 |                 36 |                   0.8723 | AI Model (Positives: loan to income ratio, savings log capped | Concerns: gig performance score, recurring expenses) |\n",
      "| Samaira |    24 |                  20000 |        5 |                  100000 | Approve    |                    100000 |                14   |                 36 |                 36 |                   1      | Rule: Strong & consistent gig worker profile.                                                                        |\n"
     ]
    }
   ],
   "source": [
    "\n",
    "EXPECTED_COLUMNS = [\n",
    "    'age', 'working_hours_per_day', 'rating', 'avg_monthly_earnings', 'savings',\n",
    "    'assets_inr', 'dependent_count', 'credit_score', 'credit_history_length_months',\n",
    "    'loan_amount_requested', 'earnings_trend_slope_6mo', 'num_loan_rejections_6mo',\n",
    "    'recurring_expenses', 'gender', 'platform_primary', 'sector', 'education',\n",
    "    'purpose_of_loan', 'location_stability', 'credit_card_user',\n",
    "    'tenure_platform_1_months', 'tenure_platform_2_months'\n",
    "]\n",
    "try:\n",
    "    # Use the full path to your new applications file\n",
    "    path_to_new_apps = r\"C:\\Users\\lavan\\OneDrive\\Desktop\\Projects\\AI_Loan_Officer_For_Gig_Workers\\notebooks\\new_applications.csv\"\n",
    "    new_applicants_df = pd.read_csv(path_to_new_apps)\n",
    "    print(f\"✅ Loaded {len(new_applicants_df)} new applications from your file.\\n\")\n",
    "\n",
    "    # --- NEW: Robustness Check ---\n",
    "    # Check for missing columns and add them with a default value (0) if they don't exist.\n",
    "    for col in EXPECTED_COLUMNS:\n",
    "        if col not in new_applicants_df.columns:\n",
    "            print(f\"⚠️ Warning: Missing column '{col}'. Adding it with a default value of 0.\")\n",
    "            new_applicants_df[col] = 0\n",
    "\n",
    "    # Apply the decision-making function to each row\n",
    "    decisions = new_applicants_df.apply(make_loan_decision, axis=1)\n",
    "    results_df = pd.json_normalize(decisions)\n",
    "    \n",
    "    # Combine original details with decision details for a comprehensive report\n",
    "    full_output_df = pd.concat([new_applicants_df.reset_index(drop=True), results_df.drop(columns=['name'])], axis=1)\n",
    "\n",
    "    # Select and reorder columns for a clean final report\n",
    "    display_cols = [\n",
    "        'name', 'age', 'avg_monthly_earnings', 'rating', 'loan_amount_requested',\n",
    "        'decision', 'final_sanctioned_amount', 'interest_rate_pct',\n",
    "        'loan_term_months', 'model_confidence_score', 'reason'\n",
    "    ]\n",
    "    final_cols = [col for col in display_cols if col in full_output_df.columns]\n",
    "\n",
    "    print(\"\\n--- 🦾 AI Loan Officer Decisions ---\")\n",
    "    print(full_output_df[final_cols].to_markdown(index=False))\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ ERROR: Could not find the file at '{path_to_new_apps}'. Please double-check the path.\")\n",
    "except Exception as e: \n",
    "    # This will catch any other errors and print them clearly.\n",
    "    print(f\"❌ An error occurred while processing new applicants: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
